{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTI Prediction Model Inference\n",
    "\n",
    "This notebook implements inference pipeline for UTI prediction:\n",
    "1. Loading trained models and parameters\n",
    "2. Data preprocessing functions\n",
    "3. Prediction pipeline with both models\n",
    "4. Confidence scoring and threshold application\n",
    "5. Example usage with sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Trained Models and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models():\n",
    "    \"\"\"Load trained models and associated parameters\"\"\"\n",
    "    try:\n",
    "        # Load models\n",
    "        rf_model = joblib.load('../models/rf_model.joblib')\n",
    "        xgb_model = joblib.load('../models/xgb_model.joblib')\n",
    "        \n",
    "        # Load scaler\n",
    "        scaler = joblib.load('../models/scaler.joblib')\n",
    "        \n",
    "        # Load optimal thresholds\n",
    "        thresholds = joblib.load('../models/optimal_thresholds.joblib')\n",
    "        \n",
    "        return {\n",
    "            'rf_model': rf_model,\n",
    "            'xgb_model': xgb_model,\n",
    "            'scaler': scaler,\n",
    "            'thresholds': thresholds\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading models: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, scaler):\n",
    "    \"\"\"Preprocess input data for prediction\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): Input data with required features\n",
    "        scaler (StandardScaler): Fitted scaler from training\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Preprocessed data ready for prediction\n",
    "    \"\"\"\n",
    "    # Define the exact feature order as used in training\n",
    "    feature_order = [\n",
    "        # Numerical features first\n",
    "        'age', 'urine_ph', 'wbc', 'rbc',\n",
    "        \n",
    "        # Categorical features\n",
    "        'frequent_urination', 'painful_urination', 'lower_abdominal_pain', \n",
    "        'cloudy_urine', 'blood_in_urine', 'fever', 'urgent_urination', \n",
    "        'foul_smelling_urine', 'nitrites', 'leukocyte_esterase',\n",
    "        'gender', 'diabetes', 'hypertension', 'bacteria'\n",
    "    ]\n",
    "    \n",
    "    # Create a copy to avoid modifying original data\n",
    "    processed_data = data.copy()\n",
    "    \n",
    "    # Ensure only the features used in training are present\n",
    "    # If any feature is missing, raise an informative error\n",
    "    missing_features = set(feature_order) - set(processed_data.columns)\n",
    "    if missing_features:\n",
    "        raise ValueError(f\"Missing features: {missing_features}. Please ensure all required features are present.\")\n",
    "    \n",
    "    # Select and reorder features exactly as they were during training\n",
    "    processed_data = processed_data[feature_order]\n",
    "    \n",
    "    # Ensure categorical binary features are 0 or 1\n",
    "    categorical_features_binary = [\n",
    "        'frequent_urination', 'painful_urination', 'lower_abdominal_pain', \n",
    "        'cloudy_urine', 'blood_in_urine', 'fever', 'urgent_urination', \n",
    "        'foul_smelling_urine', 'nitrites', 'leukocyte_esterase',\n",
    "        'diabetes', 'hypertension', 'bacteria'\n",
    "    ]\n",
    "    \n",
    "    for feature in categorical_features_binary:\n",
    "        processed_data[feature] = processed_data[feature].astype(int)\n",
    "    \n",
    "    # Encode gender as binary (assuming 'M' is 0, 'F' is 1)\n",
    "    processed_data['gender'] = processed_data['gender'].map({'M': 0, 'F': 1})\n",
    "    \n",
    "    # Scale numerical features\n",
    "    numerical_features = ['age', 'urine_ph', 'wbc', 'rbc']\n",
    "    processed_data[numerical_features] = scaler.transform(processed_data[numerical_features])\n",
    "    \n",
    "    # Convert to numpy array to avoid feature name issues\n",
    "    return processed_data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sample Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_sample(data, n_samples=15):\n",
    "    \"\"\"\n",
    "    Perform advanced stratified sampling across different UTI risk scenarios\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): Original dataset\n",
    "        n_samples (int): Total number of samples to generate\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Diverse sample representing different UTI scenarios\n",
    "    \"\"\"\n",
    "    # Define more nuanced risk categorization\n",
    "    def categorize_risk(row):\n",
    "        # High-risk criteria: multiple strong indicators of UTI\n",
    "        if (row['bacteria'] == 1 and \n",
    "            ((row['frequent_urination'] == 1) or (row['painful_urination'] == 1)) and \n",
    "            (row['fever'] == 1 or row['leukocyte_esterase'] == 1)):\n",
    "            return 'high_risk_uti'\n",
    "        \n",
    "        # Moderate risk: potential UTI indicators\n",
    "        elif ((row['leukocyte_esterase'] == 1 or row['nitrites'] == 1) and \n",
    "              (row['frequent_urination'] == 1 or row['painful_urination'] == 1)):\n",
    "            return 'moderate_risk_potential_uti'\n",
    "        \n",
    "        # Low risk with some symptoms\n",
    "        elif sum([row['frequent_urination'], row['painful_urination'], \n",
    "                  row['lower_abdominal_pain'], row['cloudy_urine']]) >= 2:\n",
    "            return 'low_risk_some_symptoms'\n",
    "        \n",
    "        # Very low risk or no UTI indicators\n",
    "        else:\n",
    "            return 'no_risk_low_symptoms'\n",
    "    \n",
    "    # Add risk category to the dataset\n",
    "    data['risk_category'] = data.apply(categorize_risk, axis=1)\n",
    "    \n",
    "    # Calculate sample distribution\n",
    "    # Ensure representation of different risk scenarios\n",
    "    category_samples = {\n",
    "        'high_risk_uti': int(n_samples * 0.3),  # 30% high-risk cases\n",
    "        'moderate_risk_potential_uti': int(n_samples * 0.3),  # 30% moderate-risk cases\n",
    "        'low_risk_some_symptoms': int(n_samples * 0.2),  # 20% low-risk cases\n",
    "        'no_risk_low_symptoms': int(n_samples * 0.2)  # 20% no-risk cases\n",
    "    }\n",
    "    \n",
    "    # Adjust for any rounding discrepancies\n",
    "    total_samples = sum(category_samples.values())\n",
    "    if total_samples < n_samples:\n",
    "        category_samples['no_risk_low_symptoms'] += (n_samples - total_samples)\n",
    "    \n",
    "    # Perform stratified sampling\n",
    "    samples = []\n",
    "    for category, count in category_samples.items():\n",
    "        # Get available samples for this category\n",
    "        category_data = data[data['risk_category'] == category]\n",
    "        \n",
    "        # If not enough samples, sample with replacement\n",
    "        if len(category_data) < count:\n",
    "            samples.append(category_data.sample(n=count, replace=True, random_state=42))\n",
    "        else:\n",
    "            samples.append(category_data.sample(n=count, random_state=42))\n",
    "    \n",
    "    # Combine samples\n",
    "    diverse_sample = pd.concat(samples, ignore_index=True)\n",
    "    \n",
    "    # Remove the temporary risk_category column\n",
    "    diverse_sample = diverse_sample.drop(columns=['risk_category'])\n",
    "    \n",
    "    return diverse_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prediction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(data, model_artifacts):\n",
    "    \"\"\"Make predictions using both models with confidence scoring\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): Input data for prediction\n",
    "        model_artifacts (dict): Dictionary containing models and parameters\n",
    "    \n",
    "    Returns:\n",
    "        dict: Prediction results and confidence scores\n",
    "    \"\"\"\n",
    "    # Preprocess data\n",
    "    processed_data = preprocess_data(data, model_artifacts['scaler'])\n",
    "    \n",
    "    # Get predictions and probabilities from both models\n",
    "    rf_proba = model_artifacts['rf_model'].predict_proba(processed_data)[:, 1]\n",
    "    xgb_proba = model_artifacts['xgb_model'].predict_proba(processed_data)[:, 1]\n",
    "    \n",
    "    # Apply optimal thresholds\n",
    "    rf_pred = (rf_proba >= model_artifacts['thresholds']['rf_threshold']).astype(int)\n",
    "    xgb_pred = (xgb_proba >= model_artifacts['thresholds']['xgb_threshold']).astype(int)\n",
    "    \n",
    "    # Calculate ensemble probability and confidence\n",
    "    ensemble_proba = (rf_proba + xgb_proba) / 2\n",
    "    prediction_agreement = (rf_pred == xgb_pred).astype(int)\n",
    "    \n",
    "    # Calculate confidence score\n",
    "    confidence_score = np.where(\n",
    "        prediction_agreement,\n",
    "        np.maximum(ensemble_proba, 1 - ensemble_proba),\n",
    "        np.minimum(ensemble_proba, 1 - ensemble_proba)\n",
    "    )\n",
    "    \n",
    "    # Prepare results\n",
    "    results = pd.DataFrame({\n",
    "        'rf_prediction': rf_pred,\n",
    "        'rf_probability': rf_proba,\n",
    "        'xgb_prediction': xgb_pred,\n",
    "        'xgb_probability': xgb_proba,\n",
    "        'ensemble_probability': ensemble_proba,\n",
    "        'confidence_score': confidence_score,\n",
    "        'models_agree': prediction_agreement\n",
    "    })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_prediction(prediction_results):\n",
    "    \"\"\"Interpret prediction results and provide recommendation\n",
    "    \n",
    "    Args:\n",
    "        prediction_results (pd.DataFrame): Results from get_prediction function\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing interpretation and recommendation\n",
    "    \"\"\"\n",
    "    for idx, row in prediction_results.iterrows():\n",
    "        interpretation = {\n",
    "            'final_prediction': 1 if row['ensemble_probability'] >= 0.5 else 0,\n",
    "            'confidence_level': 'high' if row['confidence_score'] >= 0.8 else 'medium' if row['confidence_score'] >= 0.6 else 'low',\n",
    "            'model_agreement': 'agreed' if row['models_agree'] else 'disagreed',\n",
    "            'probability': row['ensemble_probability'],\n",
    "            'recommendation': ''\n",
    "        }\n",
    "        \n",
    "        # Generate recommendation based on prediction and confidence\n",
    "        if interpretation['final_prediction'] == 1:\n",
    "            if interpretation['confidence_level'] == 'high':\n",
    "                interpretation['recommendation'] = \"High probability of UTI. Recommend immediate clinical evaluation.\"\n",
    "            elif interpretation['confidence_level'] == 'medium':\n",
    "                interpretation['recommendation'] = \"Moderate probability of UTI. Recommend clinical evaluation within 24 hours.\"\n",
    "            else:\n",
    "                interpretation['recommendation'] = \"Possible UTI. Monitor symptoms and recommend clinical evaluation if symptoms persist.\"\n",
    "        else:\n",
    "            if interpretation['confidence_level'] == 'high':\n",
    "                interpretation['recommendation'] = \"Low probability of UTI. Monitor for symptom changes.\"\n",
    "            else:\n",
    "                interpretation['recommendation'] = \"UTI unlikely but cannot be ruled out. Monitor symptoms and seek evaluation if they worsen.\"\n",
    "        \n",
    "        return interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the synthetic dataset\n",
    "data = pd.read_csv('../data/uti_synthetic_data.csv')\n",
    "\n",
    "# Load models and artifacts\n",
    "model_artifacts = load_models()\n",
    "\n",
    "if model_artifacts:\n",
    "    # Generate stratified sample data\n",
    "    sample_data = stratified_sample(data, n_samples=5)\n",
    "    print(\"\\nStratified Sample Data:\")\n",
    "    print(sample_data)\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = get_prediction(sample_data, model_artifacts)\n",
    "    print(\"\\nPrediction Results:\")\n",
    "    print(predictions)\n",
    "    \n",
    "    # Interpret results for each sample\n",
    "    print(\"\\nInterpretations:\")\n",
    "    for i in range(len(predictions)):\n",
    "        sample_interpretation = interpret_prediction(predictions.iloc[[i]])\n",
    "        print(f\"\\nSample {i+1}:\")\n",
    "        print(f\"Prediction: {'Positive' if sample_interpretation['final_prediction'] == 1 else 'Negative'}\")\n",
    "        print(f\"Confidence Level: {sample_interpretation['confidence_level']}\")\n",
    "        print(f\"Model Agreement: {sample_interpretation['model_agreement']}\")\n",
    "        print(f\"Probability: {sample_interpretation['probability']:.2f}\")\n",
    "        print(f\"Recommendation: {sample_interpretation['recommendation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Interactive Patient Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_patient_input():\n",
    "    \"\"\"Collect patient information interactively for UTI prediction\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with patient input data\n",
    "    \"\"\"\n",
    "    print(\"UTI Prediction Input Form\")\n",
    "    print(\"Please enter patient information (0 for No, 1 for Yes)\")\n",
    "    \n",
    "    # Create dictionary to store patient inputs\n",
    "    patient_data = {\n",
    "        'frequent_urination': int(input(\"Frequent urination (0/1): \")),\n",
    "        'painful_urination': int(input(\"Painful urination (0/1): \")),\n",
    "        'lower_abdominal_pain': int(input(\"Lower abdominal pain (0/1): \")),\n",
    "        'cloudy_urine': int(input(\"Cloudy urine (0/1): \")),\n",
    "        'blood_in_urine': int(input(\"Blood in urine (0/1): \")),\n",
    "        'fever': int(input(\"Fever (0/1): \")),\n",
    "        'urgent_urination': int(input(\"Urgent urination (0/1): \")),\n",
    "        'foul_smelling_urine': int(input(\"Foul-smelling urine (0/1): \")),\n",
    "        'nitrites': int(input(\"Nitrites present (0/1): \")),\n",
    "        'leukocyte_esterase': int(input(\"Leukocyte esterase present (0/1): \")),\n",
    "    }\n",
    "    \n",
    "    # Additional numerical inputs\n",
    "    patient_data['age'] = int(input(\"Patient age: \"))\n",
    "    patient_data['urine_ph'] = float(input(\"Urine pH level: \"))\n",
    "    patient_data['wbc'] = float(input(\"White Blood Cell count: \"))\n",
    "    patient_data['rbc'] = float(input(\"Red Blood Cell count: \"))\n",
    "    \n",
    "    # Categorical inputs\n",
    "    patient_data['gender'] = input(\"Gender (M/F): \").upper()\n",
    "    patient_data['diabetes'] = int(input(\"Diabetes (0/1): \"))\n",
    "    patient_data['hypertension'] = int(input(\"Hypertension (0/1): \"))\n",
    "    patient_data['bacteria'] = int(input(\"Bacteria present (0/1): \"))\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    patient_df = pd.DataFrame([patient_data])\n",
    "    \n",
    "    return patient_df\n",
    "\n",
    "def run_patient_prediction():\n",
    "    \"\"\"Run the full prediction pipeline for a single patient input\"\"\"\n",
    "    # Load models\n",
    "    model_artifacts = load_models()\n",
    "    \n",
    "    if model_artifacts:\n",
    "        # Collect patient input\n",
    "        patient_data = collect_patient_input()\n",
    "        \n",
    "        # Get prediction\n",
    "        predictions = get_prediction(patient_data, model_artifacts)\n",
    "        \n",
    "        # Interpret results\n",
    "        interpretation = interpret_prediction(predictions)\n",
    "        \n",
    "        print(\"\\n--- UTI Prediction Result ---\")\n",
    "        print(f\"Prediction: {'Positive' if interpretation['final_prediction'] == 1 else 'Negative'}\")\n",
    "        print(f\"Confidence Level: {interpretation['confidence_level']}\")\n",
    "        print(f\"Probability: {interpretation['probability']:.2f}\")\n",
    "        print(f\"Recommendation: {interpretation['recommendation']}\")\n",
    "\n",
    "# Uncomment the following line to run the interactive prediction\n",
    "run_patient_prediction()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
