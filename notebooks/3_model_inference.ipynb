{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTI Prediction Model Inference\n",
    "\n",
    "This notebook implements inference pipeline for UTI prediction:\n",
    "1. Loading trained models and parameters\n",
    "2. Data preprocessing functions\n",
    "3. Prediction pipeline with both models\n",
    "4. Confidence scoring and threshold application\n",
    "5. Example usage with sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Trained Models and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models():\n",
    "    \"\"\"Load trained models and associated parameters\"\"\"\n",
    "    try:\n",
    "        rf_model = joblib.load('../models/rf_model.joblib')\n",
    "        xgb_model = joblib.load('../models/xgb_model.joblib')\n",
    "        \n",
    "        scaler = joblib.load('../models/scaler.joblib')\n",
    "        \n",
    "        # More aggressive thresholds for medical risk\n",
    "        thresholds = {\n",
    "            'rf_threshold': 0.3,  # Lower threshold to increase sensitivity\n",
    "            'xgb_threshold': 0.3\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'rf_model': rf_model,\n",
    "            'xgb_model': xgb_model,\n",
    "            'scaler': scaler,\n",
    "            'thresholds': thresholds\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading models: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, scaler):\n",
    "    feature_order = [\n",
    "        'age', 'urine_ph', 'wbc', 'rbc',\n",
    "        'frequent_urination', 'painful_urination', 'lower_abdominal_pain', \n",
    "        'cloudy_urine', 'blood_in_urine', 'fever', 'urgent_urination', \n",
    "        'foul_smelling_urine', 'nitrites', 'leukocyte_esterase',\n",
    "        'gender', 'diabetes', 'hypertension', 'bacteria'\n",
    "    ]\n",
    "    \n",
    "    processed_data = data.copy()\n",
    "    \n",
    "    # More robust feature handling\n",
    "    for feature in feature_order:\n",
    "        if feature not in processed_data.columns:\n",
    "            processed_data[feature] = 0\n",
    "    \n",
    "    categorical_features = [\n",
    "        'frequent_urination', 'painful_urination', 'lower_abdominal_pain', \n",
    "        'cloudy_urine', 'blood_in_urine', 'fever', 'urgent_urination', \n",
    "        'foul_smelling_urine', 'nitrites', 'leukocyte_esterase',\n",
    "        'diabetes', 'hypertension', 'bacteria'\n",
    "    ]\n",
    "    \n",
    "    for feature in categorical_features:\n",
    "        processed_data[feature] = processed_data[feature].astype(int).clip(0, 1)\n",
    "    \n",
    "    processed_data['gender'] = processed_data['gender'].map({'M': 0, 'F': 1}).fillna(0).astype(int)\n",
    "    \n",
    "    numerical_features = ['age', 'urine_ph', 'wbc', 'rbc']\n",
    "    for feature in numerical_features:\n",
    "        processed_data[feature] = pd.to_numeric(processed_data[feature], errors='coerce').fillna(processed_data[feature].mean())\n",
    "    \n",
    "    processed_data = processed_data[feature_order]\n",
    "    \n",
    "    processed_data[numerical_features] = scaler.transform(processed_data[numerical_features])\n",
    "    \n",
    "    return processed_data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sample Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_sample(data, n_samples=15):\n",
    "    \"\"\"\n",
    "    Perform advanced stratified sampling across different UTI risk scenarios\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): Original dataset\n",
    "        n_samples (int): Total number of samples to generate\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Diverse sample representing different UTI scenarios\n",
    "    \"\"\"\n",
    "    # Define more nuanced risk categorization\n",
    "    def categorize_risk(row):\n",
    "        # High-risk criteria: multiple strong indicators of UTI\n",
    "        if (row['bacteria'] == 1 and \n",
    "            ((row['frequent_urination'] == 1) or (row['painful_urination'] == 1)) and \n",
    "            (row['fever'] == 1 or row['leukocyte_esterase'] == 1)):\n",
    "            return 'high_risk_uti'\n",
    "        \n",
    "        # Moderate risk: potential UTI indicators\n",
    "        elif ((row['leukocyte_esterase'] == 1 or row['nitrites'] == 1) and \n",
    "              (row['frequent_urination'] == 1 or row['painful_urination'] == 1)):\n",
    "            return 'moderate_risk_potential_uti'\n",
    "        \n",
    "        # Low risk with some symptoms\n",
    "        elif sum([row['frequent_urination'], row['painful_urination'], \n",
    "                  row['lower_abdominal_pain'], row['cloudy_urine']]) >= 2:\n",
    "            return 'low_risk_some_symptoms'\n",
    "        \n",
    "        # Very low risk or no UTI indicators\n",
    "        else:\n",
    "            return 'no_risk_low_symptoms'\n",
    "    \n",
    "    # Add risk category to the dataset\n",
    "    data['risk_category'] = data.apply(categorize_risk, axis=1)\n",
    "    \n",
    "    # Calculate sample distribution\n",
    "    # Ensure representation of different risk scenarios\n",
    "    category_samples = {\n",
    "        'high_risk_uti': int(n_samples * 0.3),  # 30% high-risk cases\n",
    "        'moderate_risk_potential_uti': int(n_samples * 0.3),  # 30% moderate-risk cases\n",
    "        'low_risk_some_symptoms': int(n_samples * 0.2),  # 20% low-risk cases\n",
    "        'no_risk_low_symptoms': int(n_samples * 0.2)  # 20% no-risk cases\n",
    "    }\n",
    "    \n",
    "    # Adjust for any rounding discrepancies\n",
    "    total_samples = sum(category_samples.values())\n",
    "    if total_samples < n_samples:\n",
    "        category_samples['no_risk_low_symptoms'] += (n_samples - total_samples)\n",
    "    \n",
    "    # Perform stratified sampling\n",
    "    samples = []\n",
    "    for category, count in category_samples.items():\n",
    "        # Get available samples for this category\n",
    "        category_data = data[data['risk_category'] == category]\n",
    "        \n",
    "        # If not enough samples, sample with replacement\n",
    "        if len(category_data) < count:\n",
    "            samples.append(category_data.sample(n=count, replace=True, random_state=42))\n",
    "        else:\n",
    "            samples.append(category_data.sample(n=count, random_state=42))\n",
    "    \n",
    "    # Combine samples\n",
    "    diverse_sample = pd.concat(samples, ignore_index=True)\n",
    "    \n",
    "    # Remove the temporary risk_category column\n",
    "    diverse_sample = diverse_sample.drop(columns=['risk_category'])\n",
    "    \n",
    "    return diverse_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prediction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(data, model_artifacts):\n",
    "    processed_data = preprocess_data(data, model_artifacts['scaler'])\n",
    "    \n",
    "    rf_proba = model_artifacts['rf_model'].predict_proba(processed_data)[:, 1]\n",
    "    xgb_proba = model_artifacts['xgb_model'].predict_proba(processed_data)[:, 1]\n",
    "    \n",
    "    # Adjust thresholds to be more sensitive\n",
    "    rf_threshold = model_artifacts['thresholds'].get('rf_threshold', 0.2)\n",
    "    xgb_threshold = model_artifacts['thresholds'].get('xgb_threshold', 0.2)\n",
    "    \n",
    "    rf_pred = (rf_proba >= rf_threshold).astype(int)\n",
    "    xgb_pred = (xgb_proba >= xgb_threshold).astype(int)\n",
    "    \n",
    "    # Enhanced risk indicators weighting\n",
    "    risk_indicators = data[['bacteria', 'nitrites', 'leukocyte_esterase', \n",
    "                            'painful_urination', 'frequent_urination', 'fever']].apply(lambda x: sum(x), axis=1)\n",
    "    \n",
    "    # More aggressive risk weighting\n",
    "    risk_weights = 1 + (risk_indicators / 3)  # Increased impact of risk indicators\n",
    "    \n",
    "    # Adjusted ensemble probability calculation\n",
    "    ensemble_proba = np.mean([\n",
    "        rf_proba * risk_weights, \n",
    "        xgb_proba * risk_weights\n",
    "    ], axis=0)\n",
    "    \n",
    "    prediction_agreement = (rf_pred == xgb_pred).astype(int)\n",
    "    \n",
    "    # More nuanced confidence calculation with higher sensitivity\n",
    "    confidence_score = np.where(\n",
    "        prediction_agreement,\n",
    "        np.maximum(ensemble_proba, 1 - ensemble_proba) * (1 + risk_indicators/2),\n",
    "        np.minimum(ensemble_proba, 1 - ensemble_proba)\n",
    "    )\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'rf_prediction': rf_pred,\n",
    "        'rf_probability': rf_proba,\n",
    "        'xgb_prediction': xgb_pred,\n",
    "        'xgb_probability': xgb_proba,\n",
    "        'ensemble_probability': ensemble_proba,\n",
    "        'confidence_score': confidence_score,\n",
    "        'models_agree': prediction_agreement,\n",
    "        'risk_indicators': risk_indicators\n",
    "    })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_prediction(prediction_results):\n",
    "    interpretations = []\n",
    "    \n",
    "    for idx, row in prediction_results.iterrows():\n",
    "        # More aggressive prediction threshold\n",
    "        final_prediction = 1 if row['ensemble_probability'] >= 0.2 else 0\n",
    "        \n",
    "        # Refined risk categorization\n",
    "        risk_indicators = row['risk_indicators']\n",
    "        if risk_indicators >= 3:\n",
    "            confidence_level = 'very high'\n",
    "        elif risk_indicators == 2:\n",
    "            confidence_level = 'high'\n",
    "        elif risk_indicators == 1:\n",
    "            confidence_level = 'medium'\n",
    "        else:\n",
    "            confidence_level = 'low'\n",
    "        \n",
    "        # More specific recommendations\n",
    "        recommendation = \"\"\n",
    "        if final_prediction == 1:\n",
    "            if confidence_level == 'very high':\n",
    "                recommendation = \"High risk of UTI. Immediate medical consultation strongly recommended.\"\n",
    "            elif confidence_level == 'high':\n",
    "                recommendation = \"Moderate to high probability of UTI. Seek medical evaluation within 12 hours.\"\n",
    "            else:\n",
    "                recommendation = \"Possible UTI. Consult healthcare provider and monitor symptoms closely.\"\n",
    "        else:\n",
    "            recommendation = \"Low UTI risk, but do not ignore persistent or worsening symptoms.\"\n",
    "        \n",
    "        interpretation = {\n",
    "            'final_prediction': final_prediction,\n",
    "            'confidence_level': confidence_level,\n",
    "            'model_agreement': 'agreed' if row['models_agree'] else 'disagreed',\n",
    "            'probability': row['ensemble_probability'],\n",
    "            'confidence_score': row['confidence_score'],\n",
    "            'risk_indicators': risk_indicators,\n",
    "            'recommendation': recommendation\n",
    "        }\n",
    "        \n",
    "        interpretations.append(interpretation)\n",
    "    \n",
    "    return interpretations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stratified Sample Data:\n",
      "       frequent_urination  painful_urination  lower_abdominal_pain  \\\n",
      "75721                   0                  0                     0   \n",
      "80184                   0                  0                     0   \n",
      "19864                   0                  1                     1   \n",
      "76699                   0                  0                     0   \n",
      "92991                   0                  0                     1   \n",
      "\n",
      "       cloudy_urine  blood_in_urine  fever  urgent_urination  \\\n",
      "75721             0               0      1                 0   \n",
      "80184             0               0      0                 0   \n",
      "19864             0               1      0                 1   \n",
      "76699             0               0      0                 0   \n",
      "92991             0               0      0                 0   \n",
      "\n",
      "       foul_smelling_urine  nitrites  leukocyte_esterase  urine_ph        age  \\\n",
      "75721                    0         0                   0  5.468306  28.962950   \n",
      "80184                    0         0                   0  4.658481  42.684099   \n",
      "19864                    0         0                   1  7.865019  34.093559   \n",
      "76699                    0         1                   0  6.025278  28.631090   \n",
      "92991                    0         0                   0  6.178109  32.891968   \n",
      "\n",
      "       gender  diabetes  hypertension        wbc       rbc  bacteria  UTI  \n",
      "75721       0         0             0   9.027298  0.054001         0    0  \n",
      "80184       0         0             0   7.812516  0.788412         0    0  \n",
      "19864       1         0             1  15.411391  3.330615         1    1  \n",
      "76699       0         0             0   5.063240  1.155861         0    0  \n",
      "92991       0         0             0   5.690272  0.865666         0    0  \n",
      "\n",
      "Prediction Results:\n",
      "       rf_prediction  rf_probability  xgb_prediction  xgb_probability  \\\n",
      "75721              0            0.00               0         0.000042   \n",
      "80184              0            0.00               0         0.000042   \n",
      "19864              0            0.02               0         0.000042   \n",
      "76699              0            0.00               0         0.000042   \n",
      "92991              0            0.00               0         0.000042   \n",
      "\n",
      "       ensemble_probability  confidence_score  models_agree  risk_indicators  \n",
      "75721              0.000028          1.499958             1                1  \n",
      "80184              0.000021          0.999979             1                0  \n",
      "19864              0.020042          2.449896             1                3  \n",
      "76699              0.000028          1.499958             1                1  \n",
      "92991              0.000021          0.999979             1                0  \n",
      "\n",
      "Interpretations:\n",
      "\n",
      "Sample 1:\n",
      "Prediction: Negative\n",
      "Confidence Level: medium\n",
      "Model Agreement: agreed\n",
      "Probability: 0.00\n",
      "Confidence Score: 1.50\n",
      "Recommendation: Low UTI risk, but do not ignore persistent or worsening symptoms.\n",
      "\n",
      "Sample 2:\n",
      "Prediction: Negative\n",
      "Confidence Level: low\n",
      "Model Agreement: agreed\n",
      "Probability: 0.00\n",
      "Confidence Score: 1.00\n",
      "Recommendation: Low UTI risk, but do not ignore persistent or worsening symptoms.\n",
      "\n",
      "Sample 3:\n",
      "Prediction: Negative\n",
      "Confidence Level: very high\n",
      "Model Agreement: agreed\n",
      "Probability: 0.02\n",
      "Confidence Score: 2.45\n",
      "Recommendation: Low UTI risk, but do not ignore persistent or worsening symptoms.\n",
      "\n",
      "Sample 4:\n",
      "Prediction: Negative\n",
      "Confidence Level: medium\n",
      "Model Agreement: agreed\n",
      "Probability: 0.00\n",
      "Confidence Score: 1.50\n",
      "Recommendation: Low UTI risk, but do not ignore persistent or worsening symptoms.\n",
      "\n",
      "Sample 5:\n",
      "Prediction: Negative\n",
      "Confidence Level: low\n",
      "Model Agreement: agreed\n",
      "Probability: 0.00\n",
      "Confidence Score: 1.00\n",
      "Recommendation: Low UTI risk, but do not ignore persistent or worsening symptoms.\n"
     ]
    }
   ],
   "source": [
    "# Load the synthetic dataset\n",
    "try:\n",
    "    data = pd.read_csv('../data/uti_synthetic_data.csv')\n",
    "    \n",
    "    # Load models and artifacts\n",
    "    model_artifacts = load_models()\n",
    "    \n",
    "    if model_artifacts:\n",
    "        # Generate a more representative sample\n",
    "        sample_data = data.sample(n=min(5, len(data)), random_state=42)\n",
    "        print(\"\\nStratified Sample Data:\")\n",
    "        print(sample_data)\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = get_prediction(sample_data, model_artifacts)\n",
    "        print(\"\\nPrediction Results:\")\n",
    "        print(predictions)\n",
    "        \n",
    "        # Interpret results for each sample\n",
    "        print(\"\\nInterpretations:\")\n",
    "        interpretations = interpret_prediction(predictions)\n",
    "        \n",
    "        for i, interpretation in enumerate(interpretations, 1):\n",
    "            print(f\"\\nSample {i}:\")\n",
    "            print(f\"Prediction: {'Positive' if interpretation['final_prediction'] == 1 else 'Negative'}\")\n",
    "            print(f\"Confidence Level: {interpretation['confidence_level']}\")\n",
    "            print(f\"Model Agreement: {interpretation['model_agreement']}\")\n",
    "            print(f\"Probability: {interpretation['probability']:.2f}\")\n",
    "            print(f\"Confidence Score: {interpretation['confidence_score']:.2f}\")\n",
    "            print(f\"Recommendation: {interpretation['recommendation']}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during execution: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
